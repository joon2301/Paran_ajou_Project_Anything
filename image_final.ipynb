{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hist_cmp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Coreight98/Paran_ajou_Project_Anything/blob/main/image_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDZtxcYX1agg"
      },
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "GoogleNet = models.googlenet(pretrained=True)\n",
        "GoogleNet.fc = nn.Linear(in_features=1024, out_features=35)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ob1SJaA1kwM",
        "outputId": "62fdaac8-5174-43a2-8a50-59ecfe88918d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import PIL\n",
        "import time\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import random\n",
        "import torch"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLpb1r4d1wQv"
      },
      "source": [
        "train_location = '/content/drive/MyDrive/data/DTD_final/'\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "class PatternDataset():\n",
        "    def __init__(self, image, mode, transforms):\n",
        "        super().__init__()\n",
        "        self.image = image\n",
        "        self.mode = mode\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_name = self.image[index]\n",
        "        image = Image.open(train_location + image_name)\n",
        "        image = image.resize((224,224))\n",
        "        #ë ˆì´ë¸” ìž…ë ¥\n",
        "        label = 1\n",
        "        label = torch.tensor(label,dtype=torch.long)\n",
        "        #ì´ë¯¸ì§€ ë³€í˜• ì ìš©ìš©\n",
        "        image = self.transforms(image)\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image)\n",
        "    def ind(index):\n",
        "      image=self.image[index]\n",
        "      return image\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAjOtwpzDdEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ce8c671-8026-48a6-e637-b0d458f22b21"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    device ='cuda'\n",
        "    if device == 'cuda':\n",
        "      torch.cuda.manual_seed_all(777)\n",
        "    SEED = 777\n",
        "    seed_everything(SEED)\n",
        "    #ë°ì´í„° ì…‹ ë¶ˆëŸ¬ì˜¤ê³  ì •ê·œí™”\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "          transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "          ]\n",
        "    )\n",
        "    train_images = os.listdir(train_location)\n",
        "    net=GoogleNet\n",
        "    PATH = '/content/drive/MyDrive/data/DTD_save/YG/New_GN/GGN_69.pth'\n",
        "    net.load_state_dict(torch.load(PATH))\n",
        "\n",
        "    net.eval()\n",
        "    X = np.load('/content/drive/MyDrive/data/DTD_save/DTD10.npy')\n",
        "    X = np.reshape(X,(3624,35))\n",
        "    Y = np.zeros((3624,1))\n",
        "    Y = np.reshape(Y,(3624,1))\n",
        "    reg = KNeighborsClassifier(n_neighbors=4)\n",
        "    reg.fit(X,Y)\n",
        "    \n",
        "    input_pth = '/content/drive/MyDrive/data/DTD_final/braided_0001.jpg'\n",
        "    img = PIL.Image.open(input_pth) ##################ì—¬ê¸°ê°€ input imageìž…ë‹ˆë‹¤ìš”\n",
        "    img = img.resize((224,224))\n",
        "    emp = torch.empty((1,3,224,224),dtype=torch.float32)\n",
        "    img_t =transform(img)\n",
        "    emp[0] = img_t\n",
        "    input = net(emp)\n",
        "    neighbor_index= reg.kneighbors(input.detach().numpy(),n_neighbors=4,return_distance=False)\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n5uRSUFiEmx"
      },
      "source": [
        "##### ì•„ì›ƒí’‹ ì´ë¯¸ì§€ 4ìž¥ ì¶œë ¥ #####\n",
        "from IPython.display import Image \n",
        "for ind in neighbor_index[0]:\n",
        "  name='/content/drive/MyDrive/data/DTD_final/%s'%(train_images[ind])\n",
        "from PIL import Image"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4r3qhjI2HLb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06d526c8-59b8-472d-e870-a716dcb570ef"
      },
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "\n",
        "%cd /content/yolov5/\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 6469, done.\u001b[K\n",
            "remote: Counting objects: 100% (187/187), done.\u001b[K\n",
            "remote: Compressing objects: 100% (139/139), done.\u001b[K\n",
            "remote: Total 6469 (delta 97), reused 113 (delta 46), pack-reused 6282\u001b[K\n",
            "Receiving objects: 100% (6469/6469), 8.69 MiB | 35.86 MiB/s, done.\n",
            "Resolving deltas: 100% (4404/4404), done.\n",
            "/content/yolov5\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.19.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n",
            "Collecting PyYAML>=5.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 645kB 28.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (0.9.1+cu101)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (4.41.1)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (2.5.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 19)) (0.11.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (1.1.5)\n",
            "Requirement already satisfied: pycocotools>=2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 29)) (2.0.2)\n",
            "Collecting thop\n",
            "  Downloading https://files.pythonhosted.org/packages/6c/8b/22ce44e1c71558161a8bd54471123cc796589c7ebbfc15a7e8932e522f83/thop-0.0.31.post2005241907-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 10)) (3.7.4.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.4.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.12.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.30.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.3.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.34.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.36.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (56.1.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 20)) (2018.9)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0->-r requirements.txt (line 29)) (0.29.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.0.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.0.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.4.1)\n",
            "Installing collected packages: PyYAML, thop\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-5.4.1 thop-0.0.31.post2005241907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FV7EuMS2NAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd28adc0-5db7-4b7f-ba1c-d90c1dc1d217"
      },
      "source": [
        "from glob import glob\n",
        "val_imgg_list = glob('/content/drive/MyDrive/á„‘á…¡á„…á…¡á†«á„’á…¡á†¨á„€á…µ/á„€á…¡á„€á…® á„‹á…µá„†á…µá„Œá…µ_á„Žá…¬á„Œá…©á†¼/images/ë¼íƒ„ì•”ì²´ì–´/*.jpg')\n",
        "\n",
        "val_img_path = val_imgg_list[0:10]\n",
        "weights_path = '/content/drive/MyDrive/data/DTD_save/best.pt'\n",
        "for item in val_img_path:\n",
        "  !python detect.py --weights \"{weights_path}\" --img 416 --conf 0.3 --source \"{item}\" --save-txt "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.3, device='', exist_ok=False, hide_conf=False, hide_labels=False, img_size=416, iou_thres=0.45, line_thickness=3, max_det=1000, name='exp', nosave=False, project='runs/detect', save_conf=False, save_crop=False, save_txt=True, source='/content/drive/MyDrive/á„‘á…¡á„…á…¡á†«á„’á…¡á†¨á„€á…µ/á„€á…¡á„€á…® á„‹á…µá„†á…µá„Œá…µ_á„Žá…¬á„Œá…©á†¼/images/ë¼íƒ„ì•”ì²´ì–´/á„…á…¡á„á…¡á†«á„‹á…¡á†·á„Žá…¦á„‹á…¥_1.jpg', update=False, view_img=False, weights=['/content/drive/MyDrive/data/DTD_save/best.pt'])\n",
            "YOLOv5 ðŸš€ v5.0-115-g407dc50 torch 1.8.1+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7067395 parameters, 0 gradients, 16.4 GFLOPS\n",
            "image 1/1 /content/drive/MyDrive/á„‘á…¡á„…á…¡á†«á„’á…¡á†¨á„€á…µ/á„€á…¡á„€á…® á„‹á…µá„†á…µá„Œá…µ_á„Žá…¬á„Œá…©á†¼/images/ë¼íƒ„ì•”ì²´ì–´/á„…á…¡á„á…¡á†«á„‹á…¡á†·á„Žá…¦á„‹á…¥_1.jpg: 416x416 1 chair, Done. (0.073s)\n",
            "Results saved to runs/detect/exp\n",
            "1 labels saved to runs/detect/exp/labels\n",
            "Done. (0.449s)\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.3, device='', exist_ok=False, hide_conf=False, hide_labels=False, img_size=416, iou_thres=0.45, line_thickness=3, max_det=1000, name='exp', nosave=False, project='runs/detect', save_conf=False, save_crop=False, save_txt=True, source='/content/drive/MyDrive/á„‘á…¡á„…á…¡á†«á„’á…¡á†¨á„€á…µ/á„€á…¡á„€á…® á„‹á…µá„†á…µá„Œá…µ_á„Žá…¬á„Œá…©á†¼/images/ë¼íƒ„ì•”ì²´ì–´/á„…á…¡á„á…¡á†«á„‹á…¡á†·á„Žá…¦á„‹á…¥_67.jpg', update=False, view_img=False, weights=['/content/drive/MyDrive/data/DTD_save/best.pt'])\n",
            "YOLOv5 ðŸš€ v5.0-115-g407dc50 torch 1.8.1+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7067395 parameters, 0 gradients, 16.4 GFLOPS\n",
            "image 1/1 /content/drive/MyDrive/á„‘á…¡á„…á…¡á†«á„’á…¡á†¨á„€á…µ/á„€á…¡á„€á…® á„‹á…µá„†á…µá„Œá…µ_á„Žá…¬á„Œá…©á†¼/images/ë¼íƒ„ì•”ì²´ì–´/á„…á…¡á„á…¡á†«á„‹á…¡á†·á„Žá…¦á„‹á…¥_67.jpg: 416x416 1 chair, Done. (0.009s)\n",
            "Results saved to runs/detect/exp2\n",
            "1 labels saved to runs/detect/exp2/labels\n",
            "Done. (0.247s)\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.3, device='', exist_ok=False, hide_conf=False, hide_labels=False, img_size=416, iou_thres=0.45, line_thickness=3, max_det=1000, name='exp', nosave=False, project='runs/detect', save_conf=False, save_crop=False, save_txt=True, source='/content/drive/MyDrive/á„‘á…¡á„…á…¡á†«á„’á…¡á†¨á„€á…µ/á„€á…¡á„€á…® á„‹á…µá„†á…µá„Œá…µ_á„Žá…¬á„Œá…©á†¼/images/ë¼íƒ„ì•”ì²´ì–´/á„…á…¡á„á…¡á†«á„‹á…¡á†·á„Žá…¦á„‹á…¥_62.jpg', update=False, view_img=False, weights=['/content/drive/MyDrive/data/DTD_save/best.pt'])\n",
            "YOLOv5 ðŸš€ v5.0-115-g407dc50 torch 1.8.1+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7067395 parameters, 0 gradients, 16.4 GFLOPS\n",
            "image 1/1 /content/drive/MyDrive/á„‘á…¡á„…á…¡á†«á„’á…¡á†¨á„€á…µ/á„€á…¡á„€á…® á„‹á…µá„†á…µá„Œá…µ_á„Žá…¬á„Œá…©á†¼/images/ë¼íƒ„ì•”ì²´ì–´/á„…á…¡á„á…¡á†«á„‹á…¡á†·á„Žá…¦á„‹á…¥_62.jpg: 416x416 1 chair, Done. (0.009s)\n",
            "Results saved to runs/detect/exp3\n",
            "1 labels saved to runs/detect/exp3/labels\n",
            "Done. (0.319s)\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.3, device='', exist_ok=False, hide_conf=False, hide_labels=False, img_size=416, iou_thres=0.45, line_thickness=3, max_det=1000, name='exp', nosave=False, project='runs/detect', save_conf=False, save_crop=False, save_txt=True, source='/content/drive/MyDrive/á„‘á…¡á„…á…¡á†«á„’á…¡á†¨á„€á…µ/á„€á…¡á„€á…® á„‹á…µá„†á…µá„Œá…µ_á„Žá…¬á„Œá…©á†¼/images/ë¼íƒ„ì•”ì²´ì–´/á„…á…¡á„á…¡á†«á„‹á…¡á†·á„Žá…¦á„‹á…¥_98.jpg', update=False, view_img=False, weights=['/content/drive/MyDrive/data/DTD_save/best.pt'])\n",
            "YOLOv5 ðŸš€ v5.0-115-g407dc50 torch 1.8.1+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7067395 parameters, 0 gradients, 16.4 GFLOPS\n",
            "image 1/1 /content/drive/MyDrive/á„‘á…¡á„…á…¡á†«á„’á…¡á†¨á„€á…µ/á„€á…¡á„€á…® á„‹á…µá„†á…µá„Œá…µ_á„Žá…¬á„Œá…©á†¼/images/ë¼íƒ„ì•”ì²´ì–´/á„…á…¡á„á…¡á†«á„‹á…¡á†·á„Žá…¦á„‹á…¥_98.jpg: 416x416 1 chair, Done. (0.009s)\n",
            "Results saved to runs/detect/exp4\n",
            "1 labels saved to runs/detect/exp4/labels\n",
            "Done. (0.374s)\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.3, device='', exist_ok=False, hide_conf=False, hide_labels=False, img_size=416, iou_thres=0.45, line_thickness=3, max_det=1000, name='exp', nosave=False, project='runs/detect', save_conf=False, save_crop=False, save_txt=True, source='/content/drive/MyDrive/á„‘á…¡á„…á…¡á†«á„’á…¡á†¨á„€á…µ/á„€á…¡á„€á…® á„‹á…µá„†á…µá„Œá…µ_á„Žá…¬á„Œá…©á†¼/images/ë¼íƒ„ì•”ì²´ì–´/á„…á…¡á„á…¡á†«á„‹á…¡á†·á„Žá…¦á„‹á…¥_123.jpg', update=False, view_img=False, weights=['/content/drive/MyDrive/data/DTD_save/best.pt'])\n",
            "YOLOv5 ðŸš€ v5.0-115-g407dc50 torch 1.8.1+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7067395 parameters, 0 gradients, 16.4 GFLOPS\n",
            "image 1/1 /content/drive/MyDrive/á„‘á…¡á„…á…¡á†«á„’á…¡á†¨á„€á…µ/á„€á…¡á„€á…® á„‹á…µá„†á…µá„Œá…µ_á„Žá…¬á„Œá…©á†¼/images/ë¼íƒ„ì•”ì²´ì–´/á„…á…¡á„á…¡á†«á„‹á…¡á†·á„Žá…¦á„‹á…¥_123.jpg: 416x416 1 chair, Done. (0.009s)\n",
            "Results saved to runs/detect/exp5\n",
            "1 labels saved to runs/detect/exp5/labels\n",
            "Done. (0.288s)\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.3, device='', exist_ok=False, hide_conf=False, hide_labels=False, img_size=416, iou_thres=0.45, line_thickness=3, max_det=1000, name='exp', nosave=False, project='runs/detect', save_conf=False, save_crop=False, save_txt=True, source='/content/drive/MyDrive/á„‘á…¡á„…á…¡á†«á„’á…¡á†¨á„€á…µ/á„€á…¡á„€á…® á„‹á…µá„†á…µá„Œá…µ_á„Žá…¬á„Œá…©á†¼/images/ë¼íƒ„ì•”ì²´ì–´/á„…á…¡á„á…¡á†«á„‹á…¡á†·á„Žá…¦á„‹á…¥_93.jpg', update=False, view_img=False, weights=['/content/drive/MyDrive/data/DTD_save/best.pt'])\n",
            "YOLOv5 ðŸš€ v5.0-115-g407dc50 torch 1.8.1+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7067395 parameters, 0 gradients, 16.4 GFLOPS\n",
            "image 1/1 /content/drive/MyDrive/á„‘á…¡á„…á…¡á†«á„’á…¡á†¨á„€á…µ/á„€á…¡á„€á…® á„‹á…µá„†á…µá„Œá…µ_á„Žá…¬á„Œá…©á†¼/images/ë¼íƒ„ì•”ì²´ì–´/á„…á…¡á„á…¡á†«á„‹á…¡á†·á„Žá…¦á„‹á…¥_93.jpg: 416x416 1 chair, Done. (0.009s)\n",
            "Results saved to runs/detect/exp6\n",
            "1 labels saved to runs/detect/exp6/labels\n",
            "Done. (0.285s)\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.3, device='', exist_ok=False, hide_conf=False, hide_labels=False, img_size=416, iou_thres=0.45, line_thickness=3, max_det=1000, name='exp', nosave=False, project='runs/detect', save_conf=False, save_crop=False, save_txt=True, source='/content/drive/MyDrive/á„‘á…¡á„…á…¡á†«á„’á…¡á†¨á„€á…µ/á„€á…¡á„€á…® á„‹á…µá„†á…µá„Œá…µ_á„Žá…¬á„Œá…©á†¼/images/ë¼íƒ„ì•”ì²´ì–´/á„…á…¡á„á…¡á†«á„‹á…¡á†·á„Žá…¦á„‹á…¥_145.jpg', update=False, view_img=False, weights=['/content/drive/MyDrive/data/DTD_save/best.pt'])\n",
            "YOLOv5 ðŸš€ v5.0-115-g407dc50 torch 1.8.1+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7067395 parameters, 0 gradients, 16.4 GFLOPS\n",
            "image 1/1 /content/drive/MyDrive/á„‘á…¡á„…á…¡á†«á„’á…¡á†¨á„€á…µ/á„€á…¡á„€á…® á„‹á…µá„†á…µá„Œá…µ_á„Žá…¬á„Œá…©á†¼/images/ë¼íƒ„ì•”ì²´ì–´/á„…á…¡á„á…¡á†«á„‹á…¡á†·á„Žá…¦á„‹á…¥_145.jpg: 416x416 1 chair, Done. (0.009s)\n",
            "Results saved to runs/detect/exp7\n",
            "1 labels saved to runs/detect/exp7/labels\n",
            "Done. (0.299s)\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.3, device='', exist_ok=False, hide_conf=False, hide_labels=False, img_size=416, iou_thres=0.45, line_thickness=3, max_det=1000, name='exp', nosave=False, project='runs/detect', save_conf=False, save_crop=False, save_txt=True, source='/content/drive/MyDrive/á„‘á…¡á„…á…¡á†«á„’á…¡á†¨á„€á…µ/á„€á…¡á„€á…® á„‹á…µá„†á…µá„Œá…µ_á„Žá…¬á„Œá…©á†¼/images/ë¼íƒ„ì•”ì²´ì–´/á„…á…¡á„á…¡á†«á„‹á…¡á†·á„Žá…¦á„‹á…¥_9.jpg', update=False, view_img=False, weights=['/content/drive/MyDrive/data/DTD_save/best.pt'])\n",
            "YOLOv5 ðŸš€ v5.0-115-g407dc50 torch 1.8.1+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7067395 parameters, 0 gradients, 16.4 GFLOPS\n",
            "image 1/1 /content/drive/MyDrive/á„‘á…¡á„…á…¡á†«á„’á…¡á†¨á„€á…µ/á„€á…¡á„€á…® á„‹á…µá„†á…µá„Œá…µ_á„Žá…¬á„Œá…©á†¼/images/ë¼íƒ„ì•”ì²´ì–´/á„…á…¡á„á…¡á†«á„‹á…¡á†·á„Žá…¦á„‹á…¥_9.jpg: 416x416 1 chair, Done. (0.009s)\n",
            "Results saved to runs/detect/exp8\n",
            "1 labels saved to runs/detect/exp8/labels\n",
            "Done. (0.265s)\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.3, device='', exist_ok=False, hide_conf=False, hide_labels=False, img_size=416, iou_thres=0.45, line_thickness=3, max_det=1000, name='exp', nosave=False, project='runs/detect', save_conf=False, save_crop=False, save_txt=True, source='/content/drive/MyDrive/á„‘á…¡á„…á…¡á†«á„’á…¡á†¨á„€á…µ/á„€á…¡á„€á…® á„‹á…µá„†á…µá„Œá…µ_á„Žá…¬á„Œá…©á†¼/images/ë¼íƒ„ì•”ì²´ì–´/á„…á…¡á„á…¡á†«á„‹á…¡á†·á„Žá…¦á„‹á…¥_22.jpg', update=False, view_img=False, weights=['/content/drive/MyDrive/data/DTD_save/best.pt'])\n",
            "YOLOv5 ðŸš€ v5.0-115-g407dc50 torch 1.8.1+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7067395 parameters, 0 gradients, 16.4 GFLOPS\n",
            "image 1/1 /content/drive/MyDrive/á„‘á…¡á„…á…¡á†«á„’á…¡á†¨á„€á…µ/á„€á…¡á„€á…® á„‹á…µá„†á…µá„Œá…µ_á„Žá…¬á„Œá…©á†¼/images/ë¼íƒ„ì•”ì²´ì–´/á„…á…¡á„á…¡á†«á„‹á…¡á†·á„Žá…¦á„‹á…¥_22.jpg: 416x416 1 chair, Done. (0.009s)\n",
            "Results saved to runs/detect/exp9\n",
            "1 labels saved to runs/detect/exp9/labels\n",
            "Done. (0.289s)\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.3, device='', exist_ok=False, hide_conf=False, hide_labels=False, img_size=416, iou_thres=0.45, line_thickness=3, max_det=1000, name='exp', nosave=False, project='runs/detect', save_conf=False, save_crop=False, save_txt=True, source='/content/drive/MyDrive/á„‘á…¡á„…á…¡á†«á„’á…¡á†¨á„€á…µ/á„€á…¡á„€á…® á„‹á…µá„†á…µá„Œá…µ_á„Žá…¬á„Œá…©á†¼/images/ë¼íƒ„ì•”ì²´ì–´/á„…á…¡á„á…¡á†«á„‹á…¡á†·á„Žá…¦á„‹á…¥_45.jpg', update=False, view_img=False, weights=['/content/drive/MyDrive/data/DTD_save/best.pt'])\n",
            "YOLOv5 ðŸš€ v5.0-115-g407dc50 torch 1.8.1+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7067395 parameters, 0 gradients, 16.4 GFLOPS\n",
            "image 1/1 /content/drive/MyDrive/á„‘á…¡á„…á…¡á†«á„’á…¡á†¨á„€á…µ/á„€á…¡á„€á…® á„‹á…µá„†á…µá„Œá…µ_á„Žá…¬á„Œá…©á†¼/images/ë¼íƒ„ì•”ì²´ì–´/á„…á…¡á„á…¡á†«á„‹á…¡á†·á„Žá…¦á„‹á…¥_45.jpg: 416x416 1 chair, Done. (0.009s)\n",
            "Results saved to runs/detect/exp10\n",
            "1 labels saved to runs/detect/exp10/labels\n",
            "Done. (0.250s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAIarvvA4yVw"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import glob\n",
        "\n",
        "output = []\n",
        "\n",
        "for i in range(1,len(val_img_path)+1):\n",
        "  if i == 1 :\n",
        "    path = '/content/yolov5/runs/detect/exp/labels/*'\n",
        "    file_list = glob.glob(path)\n",
        "  else:\n",
        "    path = '/content/yolov5/runs/detect/exp%d/labels/*'%i\n",
        "    file_list = glob.glob(path)\n",
        "  try:\n",
        "    path = file_list[0]\n",
        "    f = open(path, 'r')\n",
        "    lines = f.readlines()\n",
        "    if len(lines)>=2:\n",
        "      continue\n",
        "  except:\n",
        "    continue\n",
        "  src = cv2.imread(val_img_path[i-1], cv2.IMREAD_COLOR)\n",
        "  k=1\n",
        "  for line in lines:\n",
        "      token = line.split(' ')\n",
        "      x=float(token[1])\n",
        "      y=float(token[2])\n",
        "      w=float(token[3])\n",
        "      h=float(token[4])\n",
        "\n",
        "      x1=x-w/2\n",
        "      y1=y-h/2\n",
        "      \n",
        "      x1_pixel = int(x1*src.shape[1])\n",
        "      w_pixel = int(w*src.shape[1])\n",
        "      y1_pixel = int(y1*src.shape[0])\n",
        "      h_pixel = int(h*src.shape[0])\n",
        "      \n",
        "      rectangle = (x1_pixel,y1_pixel,w_pixel,h_pixel)\n",
        "\n",
        "      mask = np.zeros(src.shape[:2], np.uint8)\n",
        "\n",
        "      bgdModel = np.zeros((1, 65), np.float64)\n",
        "      fgdModel = np.zeros((1, 65), np.float64)\n",
        "\n",
        "      cv2.grabCut(src, # ì›ë³¸ ì´ë¯¸ì§€\n",
        "            mask,       # ë§ˆìŠ¤í¬\n",
        "            rectangle,  # ì‚¬ê°í˜•\n",
        "            bgdModel,   # ë°°ê²½ì„ ìœ„í•œ ìž„ì‹œ ë°°ì—´\n",
        "            fgdModel,   # ì „ê²½ì„ ìœ„í•œ ìž„ì‹œ ë°°ì—´\n",
        "            5,          # ë°˜ë³µ íšŸìˆ˜\n",
        "            cv2.GC_INIT_WITH_RECT) # ì‚¬ê°í˜•ì„ ìœ„í•œ ì´ˆê¸°í™”\n",
        "\n",
        "      mask_2 = np.where((mask==2) | (mask==0), 0, 1).astype('uint8')\n",
        "\n",
        "      image_rgb_nobg = src * mask_2[:, :, np.newaxis]\n",
        "      A = image_rgb_nobg[y1_pixel:(y1_pixel+h_pixel),x1_pixel:(x1_pixel+w_pixel)]\n",
        "      output.append([A,i])\n",
        "  f.close()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej9M6r0dFcAR"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "ans_arr = []\n",
        "for i in range(len(output)):\n",
        "  for j in range(4):\n",
        "    name='/content/drive/MyDrive/data/DTD_final/%s'%(train_images[neighbor_index[0][j]])\n",
        "    img1 = cv2.imread(name,0)\n",
        "    img2 = output[i][0]\n",
        "    orb = cv2.ORB_create()\n",
        "    kp1, des1 = orb.detectAndCompute(img1,None)\n",
        "    kp2, des2 = orb.detectAndCompute(img2,None)\n",
        "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "    matches = bf.match(des1,des2)\n",
        "    matches = sorted(matches, key = lambda x:x.distance)\n",
        "    if len(matches) > 120:\n",
        "      ans_arr.append(output[i][1])\n",
        "      img3 = cv2.drawMatches(img1,kp1,img2,kp2,matches[:10],None,flags=2)\n",
        "      break"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMtv2EkbLeg_"
      },
      "source": [
        "import matplotlib.image as img \n",
        "import matplotlib.pyplot as pp \n",
        "\n",
        "for i in ans_arr:\n",
        "  ndarray = img.imread(val_imgg_list[i-1]) \n",
        "  \n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}